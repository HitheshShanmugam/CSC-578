{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Hithesh Shanmugam\n",
        "## CSC 578\n",
        "## Assignment 5"
      ],
      "metadata": {
        "id": "cBP7WiakWgBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\") # my Google Drive root directory will be mapped here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6dXO3mfWGGK",
        "outputId": "19fe6e24-34ad-4a17-c652-5b65a6bb6d53"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "thisdir = '/content/drive/My Drive/Assignment 5'\n",
        "os.chdir(thisdir)\n",
        "!pwd"
      ],
      "metadata": {
        "id": "2fHumcJgWGIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1ebf5bc-cc6d-4fee-8a5f-237c9d07ba96"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Assignment 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install import-ipynb\n",
        "import import_ipynb"
      ],
      "metadata": {
        "id": "CLfp9sp3WGTL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83c14186-44d4-4c7e-c995-e33a460b5706"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: import-ipynb in /usr/local/lib/python3.7/dist-packages (0.1.4)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (7.9.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (5.7.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.18.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (2.0.10)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->IPython->import-ipynb) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->import-ipynb) (1.15.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.3.3)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.13.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (2.16.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.11.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->import-ipynb) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->import-ipynb) (3.9.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (22.1.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.10.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->import-ipynb) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import NN578_network2_nb as network2\n",
        "import numpy as np\n",
        "# Load the data (using the custom function defined in the class Notebook).\n",
        "iris_data = network2.my_load_csv('iris.csv', 4, 3)\n",
        "\n",
        "# Test with one-data Iris data\n",
        "\n",
        "inst1 = (np.array([5.7, 3, 4.2, 1.2]), np.array([0., 1., 0.]))\n",
        "x1 = np.reshape(inst1[0], (4, 1))\n",
        "y1 = np.reshape(inst1[1], (3, 1))\n",
        "sample1 = [(x1, y1)]\n",
        "inst2 = (np.array([4.8, 3.4, 1.6, 0.2]), np.array([1., 0., 0.]))\n",
        "x2 = np.reshape(inst2[0], (4, 1))\n",
        "y2 = np.reshape(inst2[1], (3, 1))\n",
        "sample2 = [(x2, y2)]\n",
        "\n",
        "net4 = network2.Network.load_network(\"iris-423.dat\")\n",
        "net4.set_parameters(cost=network2.QuadraticCost)\n",
        "\n",
        "net4.SGD(sample1, 2, 1, 1.0, evaluation_data=sample2, monitor_evaluation_cost=True, \n",
        "            monitor_evaluation_accuracy=True,\n",
        "            monitor_training_cost=True,\n",
        "            monitor_training_accuracy=True)"
      ],
      "metadata": {
        "id": "X44lFU2CWGai",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca29d39-143a-493b-a5bd-dc2543351d55"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from NN578_network2_nb.ipynb\n",
            "Training cost: 0.26673128660052947\n",
            "Training accuracy: 1.0 \n",
            "test cost: 0.3244002758397572\n",
            "test accuracy: 0.0 \n",
            "\n",
            "Training cost: 0.2107866577006649\n",
            "Training accuracy: 1.0 \n",
            "test cost: 0.37647122809828165\n",
            "test accuracy: 0.0 \n",
            "\n",
            "Training 2 epochs complete.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.26673128660052947, 0.2107866577006649],\n",
              " [1, 1],\n",
              " [0.3244002758397572, 0.37647122809828165],\n",
              " [0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris_train = network2.my_load_csv('iris-train-2.csv', 4, 3)\n",
        "iris_test = network2.my_load_csv('iris-test-2.csv', 4, 3)"
      ],
      "metadata": {
        "id": "93P9t7XJWGdO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid+Sigmoid+Cross Entropy"
      ],
      "metadata": {
        "id": "3aJImO8omuo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = network2.Network.load_network(\"iris-423.dat\")\n",
        "\n",
        "# Set hyper-parameter values individually after the network\n",
        "net2.set_parameters(cost=network2.CrossEntropyCost, \n",
        "                    act_hidden=network2.Sigmoid, act_output=network2.Sigmoid)\n",
        "\n",
        "net2.SGD(iris_train, 30, 8, 0.3, evaluation_data=iris_test, monitor_evaluation_cost=True, \n",
        "            monitor_evaluation_accuracy=True,\n",
        "            monitor_training_cost=True,\n",
        "            monitor_training_accuracy=True)"
      ],
      "metadata": {
        "id": "VZIoed5IWGio",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "261fa16d-4e4f-4c3c-cb5f-b00765e278b9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training cost: 1.9198695391361114\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.9200001793653776\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.874699590320782\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.8760418869624829\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.661601373794942\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.6629384852748312\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.5164986628018775\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.521155614974368\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.406706300759064\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.4131993926503115\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.3233097616444063\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.3300491817896165\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.2599775804030706\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.2661936021862834\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.2113959437594042\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.216887242772662\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.1734177846885114\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.1782121326111676\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.1429788498408782\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.1471651189241243\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.1176476394414578\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.1213204157041152\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.0945852990606575\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.0978728655267758\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.0681939961100826\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 1.0715474517341539\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 1.043823018205483\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.0476625563159112\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 1.0291291599590808\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.0330003911685472\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 1.0179544951810198\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 1.0215586207367489\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 1.008794893305642\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 1.0120807011311292\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 1.0011121132112557\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 1.0040834032061627\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.9945637983366118\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.9972351962034773\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.9889078091787104\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.9912970838343993\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.9839644651303822\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.9860906457942438\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.9795961639515576\n",
            "Training accuracy: 0.6857142857142857 \n",
            "test cost: 0.981479112461936\n",
            "test accuracy: 0.7333333333333333 \n",
            "\n",
            "Training cost: 0.9756949796167976\n",
            "Training accuracy: 0.7142857142857143 \n",
            "test cost: 0.9773555839878335\n",
            "test accuracy: 0.7333333333333333 \n",
            "\n",
            "Training cost: 0.9721744910747385\n",
            "Training accuracy: 0.7333333333333333 \n",
            "test cost: 0.9736351281191824\n",
            "test accuracy: 0.7333333333333333 \n",
            "\n",
            "Training cost: 0.9689640878996059\n",
            "Training accuracy: 0.7428571428571429 \n",
            "test cost: 0.9702490820906196\n",
            "test accuracy: 0.7555555555555555 \n",
            "\n",
            "Training cost: 0.9660048000274896\n",
            "Training accuracy: 0.7523809523809524 \n",
            "test cost: 0.967140566624152\n",
            "test accuracy: 0.8222222222222222 \n",
            "\n",
            "Training cost: 0.9632460463038832\n",
            "Training accuracy: 0.7619047619047619 \n",
            "test cost: 0.964260470065835\n",
            "test accuracy: 0.8444444444444444 \n",
            "\n",
            "Training cost: 0.960642843814375\n",
            "Training accuracy: 0.7619047619047619 \n",
            "test cost: 0.9615631907863987\n",
            "test accuracy: 0.8666666666666667 \n",
            "\n",
            "Training cost: 0.9581530774868237\n",
            "Training accuracy: 0.780952380952381 \n",
            "test cost: 0.9590013624897623\n",
            "test accuracy: 0.8666666666666667 \n",
            "\n",
            "Training cost: 0.9557345251032008\n",
            "Training accuracy: 0.7904761904761904 \n",
            "test cost: 0.9565188947395715\n",
            "test accuracy: 0.8888888888888888 \n",
            "\n",
            "Training 30 epochs complete.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1.9198695391361114,\n",
              "  1.874699590320782,\n",
              "  1.661601373794942,\n",
              "  1.5164986628018775,\n",
              "  1.406706300759064,\n",
              "  1.3233097616444063,\n",
              "  1.2599775804030706,\n",
              "  1.2113959437594042,\n",
              "  1.1734177846885114,\n",
              "  1.1429788498408782,\n",
              "  1.1176476394414578,\n",
              "  1.0945852990606575,\n",
              "  1.0681939961100826,\n",
              "  1.043823018205483,\n",
              "  1.0291291599590808,\n",
              "  1.0179544951810198,\n",
              "  1.008794893305642,\n",
              "  1.0011121132112557,\n",
              "  0.9945637983366118,\n",
              "  0.9889078091787104,\n",
              "  0.9839644651303822,\n",
              "  0.9795961639515576,\n",
              "  0.9756949796167976,\n",
              "  0.9721744910747385,\n",
              "  0.9689640878996059,\n",
              "  0.9660048000274896,\n",
              "  0.9632460463038832,\n",
              "  0.960642843814375,\n",
              "  0.9581530774868237,\n",
              "  0.9557345251032008],\n",
              " [35,\n",
              "  35,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  71,\n",
              "  70,\n",
              "  70,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  72,\n",
              "  75,\n",
              "  77,\n",
              "  78,\n",
              "  79,\n",
              "  80,\n",
              "  80,\n",
              "  82,\n",
              "  83],\n",
              " [1.9200001793653776,\n",
              "  1.8760418869624829,\n",
              "  1.6629384852748312,\n",
              "  1.521155614974368,\n",
              "  1.4131993926503115,\n",
              "  1.3300491817896165,\n",
              "  1.2661936021862834,\n",
              "  1.216887242772662,\n",
              "  1.1782121326111676,\n",
              "  1.1471651189241243,\n",
              "  1.1213204157041152,\n",
              "  1.0978728655267758,\n",
              "  1.0715474517341539,\n",
              "  1.0476625563159112,\n",
              "  1.0330003911685472,\n",
              "  1.0215586207367489,\n",
              "  1.0120807011311292,\n",
              "  1.0040834032061627,\n",
              "  0.9972351962034773,\n",
              "  0.9912970838343993,\n",
              "  0.9860906457942438,\n",
              "  0.981479112461936,\n",
              "  0.9773555839878335,\n",
              "  0.9736351281191824,\n",
              "  0.9702490820906196,\n",
              "  0.967140566624152,\n",
              "  0.964260470065835,\n",
              "  0.9615631907863987,\n",
              "  0.9590013624897623,\n",
              "  0.9565188947395715],\n",
              " [15,\n",
              "  15,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  33,\n",
              "  33,\n",
              "  33,\n",
              "  34,\n",
              "  37,\n",
              "  38,\n",
              "  39,\n",
              "  39,\n",
              "  40])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid+Softmax+Cross Entropy"
      ],
      "metadata": {
        "id": "xEB9bgs8m9dH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = network2.Network.load_network(\"iris-423.dat\")\n",
        "\n",
        "# Set hyper-parameter values individually after the network\n",
        "net2.set_parameters(cost=network2.CrossEntropyCost, act_hidden=network2.Sigmoid, act_output=network2.Softmax)\n",
        "\n",
        "net2.SGD(iris_train, 30, 8, 0.3, evaluation_data=iris_test, monitor_evaluation_cost=True, \n",
        "            monitor_evaluation_accuracy=True,\n",
        "            monitor_training_cost=True,\n",
        "            monitor_training_accuracy=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9e5uFeS67AL",
        "outputId": "b45bef70-8300-45c6-c34d-e13b198cc690"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training cost: 1.9405591606833863\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.9407206590013901\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.7238894808759648\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.7256676983309063\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.422143498669383\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.4312958950357029\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.2461441604355534\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.2537141246157992\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.1524510726653476\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.1559462138507282\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.099208165881325\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.0997891495262802\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.0649514486543157\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.0634108546670769\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.0401759463266633\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.0367842322603844\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.020259957719186\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.0149143821641842\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.0028441257591827\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.9945264465149384\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9874261306919541\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.9741863360758091\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9720676127050651\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.9529868076393521\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.9355299452172562\n",
            "Training accuracy: 0.7428571428571429 \n",
            "test cost: 0.915991249688709\n",
            "test accuracy: 0.7333333333333333 \n",
            "\n",
            "Training cost: 0.9722630752292387\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.968260322876226\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9174137314921053\n",
            "Training accuracy: 0.7428571428571429 \n",
            "test cost: 0.8928321536826826\n",
            "test accuracy: 0.7333333333333333 \n",
            "\n",
            "Training cost: 0.9079045345990805\n",
            "Training accuracy: 0.7428571428571429 \n",
            "test cost: 0.8791259306347311\n",
            "test accuracy: 0.7333333333333333 \n",
            "\n",
            "Training cost: 0.9613332242099746\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.9545745487200232\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9747450924133306\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.9772646786244727\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.006332650143993\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.0120230694569823\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9602385783315527\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.9599001543274303\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9315065954622019\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.8992960616349344\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.8678844959915272\n",
            "Training accuracy: 0.7714285714285715 \n",
            "test cost: 0.8233782297321824\n",
            "test accuracy: 0.8666666666666667 \n",
            "\n",
            "Training cost: 0.9758227140849882\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.9810795418778716\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9579119808158968\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.9572485540325222\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9368078412692692\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.9077334832956865\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 1.0806972569827058\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.08756523941666\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9614684801650042\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.9644947365610173\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9542406317452242\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.9545621077089251\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9298973652116803\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.9149125293550209\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.9595741932214927\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.9623295638043508\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training 30 epochs complete.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1.9405591606833863,\n",
              "  1.7238894808759648,\n",
              "  1.422143498669383,\n",
              "  1.2461441604355534,\n",
              "  1.1524510726653476,\n",
              "  1.099208165881325,\n",
              "  1.0649514486543157,\n",
              "  1.0401759463266633,\n",
              "  1.020259957719186,\n",
              "  1.0028441257591827,\n",
              "  0.9874261306919541,\n",
              "  0.9720676127050651,\n",
              "  0.9355299452172562,\n",
              "  0.9722630752292387,\n",
              "  0.9174137314921053,\n",
              "  0.9079045345990805,\n",
              "  0.9613332242099746,\n",
              "  0.9747450924133306,\n",
              "  1.006332650143993,\n",
              "  0.9602385783315527,\n",
              "  0.9315065954622019,\n",
              "  0.8678844959915272,\n",
              "  0.9758227140849882,\n",
              "  0.9579119808158968,\n",
              "  0.9368078412692692,\n",
              "  1.0806972569827058,\n",
              "  0.9614684801650042,\n",
              "  0.9542406317452242,\n",
              "  0.9298973652116803,\n",
              "  0.9595741932214927],\n",
              " [35,\n",
              "  35,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  71,\n",
              "  78,\n",
              "  70,\n",
              "  78,\n",
              "  78,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  71,\n",
              "  81,\n",
              "  70,\n",
              "  70,\n",
              "  71,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  71,\n",
              "  70],\n",
              " [1.9407206590013901,\n",
              "  1.7256676983309063,\n",
              "  1.4312958950357029,\n",
              "  1.2537141246157992,\n",
              "  1.1559462138507282,\n",
              "  1.0997891495262802,\n",
              "  1.0634108546670769,\n",
              "  1.0367842322603844,\n",
              "  1.0149143821641842,\n",
              "  0.9945264465149384,\n",
              "  0.9741863360758091,\n",
              "  0.9529868076393521,\n",
              "  0.915991249688709,\n",
              "  0.968260322876226,\n",
              "  0.8928321536826826,\n",
              "  0.8791259306347311,\n",
              "  0.9545745487200232,\n",
              "  0.9772646786244727,\n",
              "  1.0120230694569823,\n",
              "  0.9599001543274303,\n",
              "  0.8992960616349344,\n",
              "  0.8233782297321824,\n",
              "  0.9810795418778716,\n",
              "  0.9572485540325222,\n",
              "  0.9077334832956865,\n",
              "  1.08756523941666,\n",
              "  0.9644947365610173,\n",
              "  0.9545621077089251,\n",
              "  0.9149125293550209,\n",
              "  0.9623295638043508],\n",
              " [15,\n",
              "  15,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  31,\n",
              "  33,\n",
              "  30,\n",
              "  33,\n",
              "  33,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  31,\n",
              "  39,\n",
              "  30,\n",
              "  30,\n",
              "  31,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  31,\n",
              "  30])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid+Softmax+LogLikelihood"
      ],
      "metadata": {
        "id": "fOk5-byBnMUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = network2.Network.load_network(\"iris-423.dat\")\n",
        "\n",
        "# Set hyper-parameter values individually after the network\n",
        "net2.set_parameters(cost=network2.LogLikelihood, \n",
        "                    act_hidden=network2.Sigmoid, act_output=network2.Softmax)\n",
        "\n",
        "net2.SGD(iris_train, 30, 8, 0.3, evaluation_data=iris_test, monitor_evaluation_cost=True, \n",
        "            monitor_evaluation_accuracy=True,\n",
        "            monitor_training_cost=True,\n",
        "            monitor_training_accuracy=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcQoIkJg6-DU",
        "outputId": "fd34f50c-bc87-4805-fb58-b98ad55d806c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training cost: 1.1088910600202424\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1089815487209893\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.0927369943081378\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.0931051573587698\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.9343006677822852\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.9351354709895162\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.8019004093043582\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.8039617001884208\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.7199120183203331\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.7229874087336711\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.6648712226538592\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.667866803635735\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.6268001768404559\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.6293399655933316\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.5995008365498908\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.6015307735175446\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.5791856681176732\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.5807422873159006\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.5635349223177285\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.5646647820444016\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.5510841952487571\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.5518225828193201\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.5408581253025373\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.5412251066458036\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.5321447010536879\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.5321451959078204\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.5243203168254011\n",
            "Training accuracy: 0.6857142857142857 \n",
            "test cost: 0.5239454189777131\n",
            "test accuracy: 0.7333333333333333 \n",
            "\n",
            "Training cost: 0.5166360596346398\n",
            "Training accuracy: 0.6952380952380952 \n",
            "test cost: 0.5158690729652888\n",
            "test accuracy: 0.7333333333333333 \n",
            "\n",
            "Training cost: 0.5080091786700841\n",
            "Training accuracy: 0.7333333333333333 \n",
            "test cost: 0.5068432309029365\n",
            "test accuracy: 0.7333333333333333 \n",
            "\n",
            "Training cost: 0.4980445160436068\n",
            "Training accuracy: 0.7619047619047619 \n",
            "test cost: 0.4964412679165529\n",
            "test accuracy: 0.8444444444444444 \n",
            "\n",
            "Training cost: 0.48832107788757134\n",
            "Training accuracy: 0.780952380952381 \n",
            "test cost: 0.4860204331036678\n",
            "test accuracy: 0.8666666666666667 \n",
            "\n",
            "Training cost: 0.4786082559263885\n",
            "Training accuracy: 0.8095238095238095 \n",
            "test cost: 0.47479532121806256\n",
            "test accuracy: 0.9111111111111111 \n",
            "\n",
            "Training cost: 0.46789795223978914\n",
            "Training accuracy: 0.8476190476190476 \n",
            "test cost: 0.46135111749218166\n",
            "test accuracy: 0.9111111111111111 \n",
            "\n",
            "Training cost: 0.45651231970592193\n",
            "Training accuracy: 0.8476190476190476 \n",
            "test cost: 0.4462044666052665\n",
            "test accuracy: 0.9111111111111111 \n",
            "\n",
            "Training cost: 0.4459554405476645\n",
            "Training accuracy: 0.8476190476190476 \n",
            "test cost: 0.43149226899335474\n",
            "test accuracy: 0.9111111111111111 \n",
            "\n",
            "Training cost: 0.43390140450066583\n",
            "Training accuracy: 0.8571428571428571 \n",
            "test cost: 0.41571560253583495\n",
            "test accuracy: 0.9555555555555556 \n",
            "\n",
            "Training cost: 0.4181298330495188\n",
            "Training accuracy: 0.9047619047619048 \n",
            "test cost: 0.396143716887782\n",
            "test accuracy: 0.9777777777777777 \n",
            "\n",
            "Training cost: 0.4124205889297185\n",
            "Training accuracy: 0.8571428571428571 \n",
            "test cost: 0.3856808592083516\n",
            "test accuracy: 0.9555555555555556 \n",
            "\n",
            "Training cost: 0.44915871807995394\n",
            "Training accuracy: 0.7428571428571429 \n",
            "test cost: 0.4238540460209955\n",
            "test accuracy: 0.7333333333333333 \n",
            "\n",
            "Training cost: 0.44556994237657815\n",
            "Training accuracy: 0.7428571428571429 \n",
            "test cost: 0.41792113107745554\n",
            "test accuracy: 0.7555555555555555 \n",
            "\n",
            "Training cost: 0.3798887580607503\n",
            "Training accuracy: 0.9047619047619048 \n",
            "test cost: 0.34292202888148277\n",
            "test accuracy: 0.9777777777777777 \n",
            "\n",
            "Training cost: 0.3975321833919171\n",
            "Training accuracy: 0.8571428571428571 \n",
            "test cost: 0.3624779580028236\n",
            "test accuracy: 0.9555555555555556 \n",
            "\n",
            "Training cost: 0.41207977407072255\n",
            "Training accuracy: 0.780952380952381 \n",
            "test cost: 0.37343480920513006\n",
            "test accuracy: 0.8888888888888888 \n",
            "\n",
            "Training 30 epochs complete.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1.1088910600202424,\n",
              "  1.0927369943081378,\n",
              "  0.9343006677822852,\n",
              "  0.8019004093043582,\n",
              "  0.7199120183203331,\n",
              "  0.6648712226538592,\n",
              "  0.6268001768404559,\n",
              "  0.5995008365498908,\n",
              "  0.5791856681176732,\n",
              "  0.5635349223177285,\n",
              "  0.5510841952487571,\n",
              "  0.5408581253025373,\n",
              "  0.5321447010536879,\n",
              "  0.5243203168254011,\n",
              "  0.5166360596346398,\n",
              "  0.5080091786700841,\n",
              "  0.4980445160436068,\n",
              "  0.48832107788757134,\n",
              "  0.4786082559263885,\n",
              "  0.46789795223978914,\n",
              "  0.45651231970592193,\n",
              "  0.4459554405476645,\n",
              "  0.43390140450066583,\n",
              "  0.4181298330495188,\n",
              "  0.4124205889297185,\n",
              "  0.44915871807995394,\n",
              "  0.44556994237657815,\n",
              "  0.3798887580607503,\n",
              "  0.3975321833919171,\n",
              "  0.41207977407072255],\n",
              " [35,\n",
              "  35,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  72,\n",
              "  73,\n",
              "  77,\n",
              "  80,\n",
              "  82,\n",
              "  85,\n",
              "  89,\n",
              "  89,\n",
              "  89,\n",
              "  90,\n",
              "  95,\n",
              "  90,\n",
              "  78,\n",
              "  78,\n",
              "  95,\n",
              "  90,\n",
              "  82],\n",
              " [1.1089815487209893,\n",
              "  1.0931051573587698,\n",
              "  0.9351354709895162,\n",
              "  0.8039617001884208,\n",
              "  0.7229874087336711,\n",
              "  0.667866803635735,\n",
              "  0.6293399655933316,\n",
              "  0.6015307735175446,\n",
              "  0.5807422873159006,\n",
              "  0.5646647820444016,\n",
              "  0.5518225828193201,\n",
              "  0.5412251066458036,\n",
              "  0.5321451959078204,\n",
              "  0.5239454189777131,\n",
              "  0.5158690729652888,\n",
              "  0.5068432309029365,\n",
              "  0.4964412679165529,\n",
              "  0.4860204331036678,\n",
              "  0.47479532121806256,\n",
              "  0.46135111749218166,\n",
              "  0.4462044666052665,\n",
              "  0.43149226899335474,\n",
              "  0.41571560253583495,\n",
              "  0.396143716887782,\n",
              "  0.3856808592083516,\n",
              "  0.4238540460209955,\n",
              "  0.41792113107745554,\n",
              "  0.34292202888148277,\n",
              "  0.3624779580028236,\n",
              "  0.37343480920513006],\n",
              " [15,\n",
              "  15,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  33,\n",
              "  33,\n",
              "  33,\n",
              "  38,\n",
              "  39,\n",
              "  41,\n",
              "  41,\n",
              "  41,\n",
              "  41,\n",
              "  43,\n",
              "  44,\n",
              "  43,\n",
              "  33,\n",
              "  34,\n",
              "  44,\n",
              "  43,\n",
              "  40])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReLU+Softmax+LogLikelihood"
      ],
      "metadata": {
        "id": "0ZPH8mT9neT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = network2.Network.load_network(\"iris-423.dat\")\n",
        "\n",
        "# Set hyper-parameter values individually after the network\n",
        "net2.set_parameters(cost=network2.LogLikelihood, act_hidden=network2.ReLU, act_output=network2.Softmax)\n",
        "net2.SGD(iris_train, 30, 8, 0.3, evaluation_data=iris_test, monitor_evaluation_cost=True, \n",
        "            monitor_evaluation_accuracy=True,\n",
        "            monitor_training_cost=True,\n",
        "            monitor_training_accuracy=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6Mcawba_Q-s",
        "outputId": "361513f3-e3a2-47ee-de07-59367e849718"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training cost: 1.1032307316727308\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1032307316727301\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.101670022793955\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016700227939564\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016633486223086\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016633486223073\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016803988228636\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016803988228636\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016849277809169\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.101684927780917\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.101685884169142\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016858841691424\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.101686070951269\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.101686070951269\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016861055181468\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861055181473\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016861115029026\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861115029035\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.101686112425725\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861124257258\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016861125331376\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125331374\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016861125334783\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125334787\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016861125278576\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125278579\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016861125252218\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125252224\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016861125242965\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125242974\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.101686112524009\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125240083\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.101686112523924\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125239237\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016861125239001\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125239001\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016861125238913\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125238937\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016861125238921\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.101686112523892\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016861125238906\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125238906\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016861125238906\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125238906\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.1016861125238897\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125238906\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.101686112523891\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125238913\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.101686112523891\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125238908\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.101686112523891\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125238908\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.101686112523891\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125238904\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.101686112523891\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125238904\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.101686112523891\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125238904\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.101686112523891\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.1016861125238904\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training 30 epochs complete.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1.1032307316727308,\n",
              "  1.101670022793955,\n",
              "  1.1016633486223086,\n",
              "  1.1016803988228636,\n",
              "  1.1016849277809169,\n",
              "  1.101685884169142,\n",
              "  1.101686070951269,\n",
              "  1.1016861055181468,\n",
              "  1.1016861115029026,\n",
              "  1.101686112425725,\n",
              "  1.1016861125331376,\n",
              "  1.1016861125334783,\n",
              "  1.1016861125278576,\n",
              "  1.1016861125252218,\n",
              "  1.1016861125242965,\n",
              "  1.101686112524009,\n",
              "  1.101686112523924,\n",
              "  1.1016861125239001,\n",
              "  1.1016861125238913,\n",
              "  1.1016861125238921,\n",
              "  1.1016861125238906,\n",
              "  1.1016861125238906,\n",
              "  1.1016861125238897,\n",
              "  1.101686112523891,\n",
              "  1.101686112523891,\n",
              "  1.101686112523891,\n",
              "  1.101686112523891,\n",
              "  1.101686112523891,\n",
              "  1.101686112523891,\n",
              "  1.101686112523891],\n",
              " [35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35],\n",
              " [1.1032307316727301,\n",
              "  1.1016700227939564,\n",
              "  1.1016633486223073,\n",
              "  1.1016803988228636,\n",
              "  1.101684927780917,\n",
              "  1.1016858841691424,\n",
              "  1.101686070951269,\n",
              "  1.1016861055181473,\n",
              "  1.1016861115029035,\n",
              "  1.1016861124257258,\n",
              "  1.1016861125331374,\n",
              "  1.1016861125334787,\n",
              "  1.1016861125278579,\n",
              "  1.1016861125252224,\n",
              "  1.1016861125242974,\n",
              "  1.1016861125240083,\n",
              "  1.1016861125239237,\n",
              "  1.1016861125239001,\n",
              "  1.1016861125238937,\n",
              "  1.101686112523892,\n",
              "  1.1016861125238906,\n",
              "  1.1016861125238906,\n",
              "  1.1016861125238906,\n",
              "  1.1016861125238913,\n",
              "  1.1016861125238908,\n",
              "  1.1016861125238908,\n",
              "  1.1016861125238904,\n",
              "  1.1016861125238904,\n",
              "  1.1016861125238904,\n",
              "  1.1016861125238904],\n",
              " [15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tanh+Sigmoid+Quadratic "
      ],
      "metadata": {
        "id": "pMIaH2PnnmML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = network2.Network.load_network(\"iris-423.dat\")\n",
        "\n",
        "# Set hyper-parameter values individually after the network\n",
        "net2.set_parameters(cost=network2.QuadraticCost, act_hidden=network2.Tanh, act_output=network2.Sigmoid)\n",
        "\n",
        "net2.SGD(iris_train, 30, 8, 0.3, evaluation_data=iris_test, monitor_evaluation_cost=True, \n",
        "            monitor_evaluation_accuracy=True,\n",
        "            monitor_training_cost=True,\n",
        "            monitor_training_accuracy=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRNf73WM_e2b",
        "outputId": "94c069cd-85db-461a-fcc9-c89fa082bd47"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training cost: 0.35421693181218045\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.35422590494878814\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3388079960427264\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33881486948082007\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33517665739354124\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33517634985580885\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33410934674722326\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.334101259521078\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3335486035352765\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33353281987584854\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3326501119358381\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3326360108688271\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.32765438551151715\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3279099571818368\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.2957217467901455\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.2965070887594991\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.25395022958552566\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.25442607595662836\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.22760011737824065\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.2278424520633625\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.21157842407256508\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.21171226242684144\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.2013902551200217\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.20147311828546874\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.19459597297298298\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.19465759280081507\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.18985614511996712\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.18991279917043127\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.18641060436153567\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.18647074377535067\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.18381353237497688\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.18388053455809522\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.18179435478238343\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.18186842061715175\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.18018302248213128\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.180262704971926\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.17886892719784162\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.17895223580628344\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.17777769214942676\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.17786272952352258\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.17685770387811953\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.17694293176880005\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.1760720934968687\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.1761563787034777\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.1753938352966714\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.1754763974721828\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.1748026660238482\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.1748829982334643\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.17428309201456896\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.17436088595366686\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.17382306329691197\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.17389814939509785\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.17341306800672873\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.1734853710211837\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.1730454990304055\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.1731150064582253\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.17271420158690176\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.17278094171209363\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training cost: 0.17241414395812246\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.1724781707997836\n",
            "test accuracy: 0.6888888888888889 \n",
            "\n",
            "Training 30 epochs complete.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.35421693181218045,\n",
              "  0.3388079960427264,\n",
              "  0.33517665739354124,\n",
              "  0.33410934674722326,\n",
              "  0.3335486035352765,\n",
              "  0.3326501119358381,\n",
              "  0.32765438551151715,\n",
              "  0.2957217467901455,\n",
              "  0.25395022958552566,\n",
              "  0.22760011737824065,\n",
              "  0.21157842407256508,\n",
              "  0.2013902551200217,\n",
              "  0.19459597297298298,\n",
              "  0.18985614511996712,\n",
              "  0.18641060436153567,\n",
              "  0.18381353237497688,\n",
              "  0.18179435478238343,\n",
              "  0.18018302248213128,\n",
              "  0.17886892719784162,\n",
              "  0.17777769214942676,\n",
              "  0.17685770387811953,\n",
              "  0.1760720934968687,\n",
              "  0.1753938352966714,\n",
              "  0.1748026660238482,\n",
              "  0.17428309201456896,\n",
              "  0.17382306329691197,\n",
              "  0.17341306800672873,\n",
              "  0.1730454990304055,\n",
              "  0.17271420158690176,\n",
              "  0.17241414395812246],\n",
              " [35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71,\n",
              "  71],\n",
              " [0.35422590494878814,\n",
              "  0.33881486948082007,\n",
              "  0.33517634985580885,\n",
              "  0.334101259521078,\n",
              "  0.33353281987584854,\n",
              "  0.3326360108688271,\n",
              "  0.3279099571818368,\n",
              "  0.2965070887594991,\n",
              "  0.25442607595662836,\n",
              "  0.2278424520633625,\n",
              "  0.21171226242684144,\n",
              "  0.20147311828546874,\n",
              "  0.19465759280081507,\n",
              "  0.18991279917043127,\n",
              "  0.18647074377535067,\n",
              "  0.18388053455809522,\n",
              "  0.18186842061715175,\n",
              "  0.180262704971926,\n",
              "  0.17895223580628344,\n",
              "  0.17786272952352258,\n",
              "  0.17694293176880005,\n",
              "  0.1761563787034777,\n",
              "  0.1754763974721828,\n",
              "  0.1748829982334643,\n",
              "  0.17436088595366686,\n",
              "  0.17389814939509785,\n",
              "  0.1734853710211837,\n",
              "  0.1731150064582253,\n",
              "  0.17278094171209363,\n",
              "  0.1724781707997836],\n",
              " [15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31,\n",
              "  31])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid+Sigmoid+Quadratic+L2 Regularizer"
      ],
      "metadata": {
        "id": "W0jaTY96ntMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = network2.Network.load_network(\"iris-423.dat\")\n",
        "\n",
        "# Set hyper-parameter values individually after the network\n",
        "net2.set_parameters(cost=network2.QuadraticCost,regularization='L2',\n",
        "                    act_hidden=network2.Sigmoid, act_output=network2.Sigmoid)\n",
        "\n",
        "net2.SGD(iris_train, 30, 8, 0.3,lmbda_val=2.0, evaluation_data=iris_test, monitor_evaluation_cost=True, \n",
        "            monitor_evaluation_accuracy=True,\n",
        "            monitor_training_cost=True,\n",
        "            monitor_training_accuracy=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDRBCPhM_paR",
        "outputId": "5c1a9ca9-ee91-4153-8b52-5a851c7c972a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training cost: 0.48424949464009637\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.6498324795288544\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.4453661328101058\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.5826108254131572\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.4233302886501371\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.5390362729662498\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.4078664175765557\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.5062954019316814\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.395229575154493\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.4794588840744066\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.383304050897092\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.45585952106715055\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.37022803649894903\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.43353936040740504\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.357208426652085\n",
            "Training accuracy: 0.5619047619047619 \n",
            "test cost: 0.41378606011976704\n",
            "test accuracy: 0.6444444444444445 \n",
            "\n",
            "Training cost: 0.3481116801479865\n",
            "Training accuracy: 0.6476190476190476 \n",
            "test cost: 0.40016677158455305\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.34154586241843576\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.39069016488709546\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.3361186343550277\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.3834650110394918\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.33147887278511673\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.37783922351626464\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.32740364297909835\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.37340555124954905\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.32372537491368614\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.3698737248291204\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.32033562726010023\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.3670566262173731\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.31720723596058065\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.36487672430135487\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.3143985234043124\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.3633405121902737\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.3119712901614056\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.3624322546527219\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.30990352803225263\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.36203875869100804\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.30812006986896595\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.36200557637053865\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.30655551325208513\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.3622088332656099\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.30516896303426166\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.3625672118049275\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.3039347097949996\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.3630276231302807\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.3028342645520615\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.36355301130418166\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.3018528447298474\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.3641159639327928\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.3009779027144316\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.36469552431798286\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.30019836503060016\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.36527544327119676\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.29950419802148065\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.3658431282251503\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.29888618293370556\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.3663889646352484\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.2983358240139232\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.36690583809434796\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training 30 epochs complete.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.48424949464009637,\n",
              "  0.4453661328101058,\n",
              "  0.4233302886501371,\n",
              "  0.4078664175765557,\n",
              "  0.395229575154493,\n",
              "  0.383304050897092,\n",
              "  0.37022803649894903,\n",
              "  0.357208426652085,\n",
              "  0.3481116801479865,\n",
              "  0.34154586241843576,\n",
              "  0.3361186343550277,\n",
              "  0.33147887278511673,\n",
              "  0.32740364297909835,\n",
              "  0.32372537491368614,\n",
              "  0.32033562726010023,\n",
              "  0.31720723596058065,\n",
              "  0.3143985234043124,\n",
              "  0.3119712901614056,\n",
              "  0.30990352803225263,\n",
              "  0.30812006986896595,\n",
              "  0.30655551325208513,\n",
              "  0.30516896303426166,\n",
              "  0.3039347097949996,\n",
              "  0.3028342645520615,\n",
              "  0.3018528447298474,\n",
              "  0.3009779027144316,\n",
              "  0.30019836503060016,\n",
              "  0.29950419802148065,\n",
              "  0.29888618293370556,\n",
              "  0.2983358240139232],\n",
              " [35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  59,\n",
              "  68,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70],\n",
              " [0.6498324795288544,\n",
              "  0.5826108254131572,\n",
              "  0.5390362729662498,\n",
              "  0.5062954019316814,\n",
              "  0.4794588840744066,\n",
              "  0.45585952106715055,\n",
              "  0.43353936040740504,\n",
              "  0.41378606011976704,\n",
              "  0.40016677158455305,\n",
              "  0.39069016488709546,\n",
              "  0.3834650110394918,\n",
              "  0.37783922351626464,\n",
              "  0.37340555124954905,\n",
              "  0.3698737248291204,\n",
              "  0.3670566262173731,\n",
              "  0.36487672430135487,\n",
              "  0.3633405121902737,\n",
              "  0.3624322546527219,\n",
              "  0.36203875869100804,\n",
              "  0.36200557637053865,\n",
              "  0.3622088332656099,\n",
              "  0.3625672118049275,\n",
              "  0.3630276231302807,\n",
              "  0.36355301130418166,\n",
              "  0.3641159639327928,\n",
              "  0.36469552431798286,\n",
              "  0.36527544327119676,\n",
              "  0.3658431282251503,\n",
              "  0.3663889646352484,\n",
              "  0.36690583809434796],\n",
              " [15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  29,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid+Sigmoid+Quadratic+L1 Regularizer"
      ],
      "metadata": {
        "id": "rlPzL1seoAc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = network2.Network.load_network(\"iris-423.dat\")\n",
        "\n",
        "# Set hyper-parameter values individually after the network\n",
        "net2.set_parameters(cost=network2.QuadraticCost,regularization='L1',\n",
        "                    act_hidden=network2.Sigmoid, act_output=network2.Sigmoid)\n",
        "\n",
        "net2.SGD(iris_train, 30, 8, 0.3,lmbda_val=2.0, evaluation_data=iris_test, monitor_evaluation_cost=True, \n",
        "            monitor_evaluation_accuracy=True,\n",
        "            monitor_training_cost=True,\n",
        "            monitor_training_accuracy=True)"
      ],
      "metadata": {
        "id": "ZUkd5Wz7ADyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99eda560-15d4-40b3-c732-4809a46baf6d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training cost: 0.4514329325959878\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.5741342057631584\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.42410301468179334\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.5347652946693666\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.4112952445943878\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.5120726039543707\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.403176188914966\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.49520209036870855\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3969118141689989\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.4808675848146956\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.39125754195432993\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.46762111631736347\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.38608791708845386\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.4552472129799957\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3811057467521249\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.44349673380207744\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3764592687294954\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.43268747734028656\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3724594705183074\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.4231134207751342\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.36856386370390803\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.4139779066692694\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3648860651453558\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.40513268439311306\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.36105406720297495\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3962332740574532\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3574438523593555\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.38768069846708647\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.35412721995673435\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3796581147895077\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.35104818593585185\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3726253159412353\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.348105608222102\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3657895939529627\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.34534203895661386\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.35946592493582047\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3424310892287243\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.35283855430526706\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3400405075154587\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3472742756830743\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33823946781325803\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3430090948796825\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.336692785479309\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33940185123207983\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3354420912408093\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3363963483618701\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3354122059768815\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33636712123854207\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33540088491031955\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33635897248120344\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33519810245264625\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.335967186020029\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3353169772081875\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33621258153800915\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33532211235077786\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33624519886372783\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33532213708124525\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3362433257813913\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33529178538002463\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3361837023303751\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training 30 epochs complete.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.4514329325959878,\n",
              "  0.42410301468179334,\n",
              "  0.4112952445943878,\n",
              "  0.403176188914966,\n",
              "  0.3969118141689989,\n",
              "  0.39125754195432993,\n",
              "  0.38608791708845386,\n",
              "  0.3811057467521249,\n",
              "  0.3764592687294954,\n",
              "  0.3724594705183074,\n",
              "  0.36856386370390803,\n",
              "  0.3648860651453558,\n",
              "  0.36105406720297495,\n",
              "  0.3574438523593555,\n",
              "  0.35412721995673435,\n",
              "  0.35104818593585185,\n",
              "  0.348105608222102,\n",
              "  0.34534203895661386,\n",
              "  0.3424310892287243,\n",
              "  0.3400405075154587,\n",
              "  0.33823946781325803,\n",
              "  0.336692785479309,\n",
              "  0.3354420912408093,\n",
              "  0.3354122059768815,\n",
              "  0.33540088491031955,\n",
              "  0.33519810245264625,\n",
              "  0.3353169772081875,\n",
              "  0.33532211235077786,\n",
              "  0.33532213708124525,\n",
              "  0.33529178538002463],\n",
              " [35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35],\n",
              " [0.5741342057631584,\n",
              "  0.5347652946693666,\n",
              "  0.5120726039543707,\n",
              "  0.49520209036870855,\n",
              "  0.4808675848146956,\n",
              "  0.46762111631736347,\n",
              "  0.4552472129799957,\n",
              "  0.44349673380207744,\n",
              "  0.43268747734028656,\n",
              "  0.4231134207751342,\n",
              "  0.4139779066692694,\n",
              "  0.40513268439311306,\n",
              "  0.3962332740574532,\n",
              "  0.38768069846708647,\n",
              "  0.3796581147895077,\n",
              "  0.3726253159412353,\n",
              "  0.3657895939529627,\n",
              "  0.35946592493582047,\n",
              "  0.35283855430526706,\n",
              "  0.3472742756830743,\n",
              "  0.3430090948796825,\n",
              "  0.33940185123207983,\n",
              "  0.3363963483618701,\n",
              "  0.33636712123854207,\n",
              "  0.33635897248120344,\n",
              "  0.335967186020029,\n",
              "  0.33621258153800915,\n",
              "  0.33624519886372783,\n",
              "  0.3362433257813913,\n",
              "  0.3361837023303751],\n",
              " [15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid+Sigmoid+Quadratic+Droupoutpercent=0.3"
      ],
      "metadata": {
        "id": "CJPZJGN0oDXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = network2.Network.load_network(\"iris4-20-7-3.dat\")\n",
        "\n",
        "# Set hyper-parameter values individually after the network\n",
        "net2.set_parameters(cost=network2.QuadraticCost, act_hidden=network2.Sigmoid, act_output=network2.Sigmoid, dropoutpercent=0.3)\n",
        "\n",
        "net2.SGD(iris_train, 30, 8, 0.3, evaluation_data=iris_test, monitor_evaluation_cost=True, \n",
        "            monitor_evaluation_accuracy=True,\n",
        "            monitor_training_cost=True,\n",
        "            monitor_training_accuracy=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7bEXPfFIKj6",
        "outputId": "e57cf123-3e01-4d58-de51-e0cb6bd7b8a8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training cost: 0.33577914804630565\n",
            "Training accuracy: 0.01904761904761905 \n",
            "test cost: 0.33573267785711736\n",
            "test accuracy: 0.0 \n",
            "\n",
            "Training cost: 0.33508456241529244\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3350332989073186\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3343179884249938\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3342872215829874\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33425648507072697\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33422277576327025\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3342908297971832\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33427794828497714\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3342159409068874\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.334205492986327\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33440104099959717\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33438390534703133\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33441243786217806\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3343888246884619\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3340968304282773\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33405409719761914\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3338022605496495\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33376495500642805\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3335775730633717\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33353676097728774\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.333697489998927\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3336291442682521\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33342520618667776\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3333625585105671\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3341291666667098\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3340683029588867\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3337477693701297\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3336706817059606\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3338788522560254\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3337956272371163\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3324372608839158\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3323520553952923\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3325440802095975\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3324554544696766\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33273515910082024\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33263740186562957\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3331450504449287\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3330487635663176\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33319553659765677\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3330867143697134\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3327368696232528\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3325976917707962\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3315417434680887\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33138995330127385\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.33150216980559727\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33133967138896986\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3307428256961301\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.33056143490589013\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3306533923995788\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3304431227005986\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.32990586460631843\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3297251351104058\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.3283420289800067\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3281534840583845\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 0.32786998601648065\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.3276810912531726\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.3280172910000471\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 0.3278346357872153\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training 30 epochs complete.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.33577914804630565,\n",
              "  0.33508456241529244,\n",
              "  0.3343179884249938,\n",
              "  0.33425648507072697,\n",
              "  0.3342908297971832,\n",
              "  0.3342159409068874,\n",
              "  0.33440104099959717,\n",
              "  0.33441243786217806,\n",
              "  0.3340968304282773,\n",
              "  0.3338022605496495,\n",
              "  0.3335775730633717,\n",
              "  0.333697489998927,\n",
              "  0.33342520618667776,\n",
              "  0.3341291666667098,\n",
              "  0.3337477693701297,\n",
              "  0.3338788522560254,\n",
              "  0.3324372608839158,\n",
              "  0.3325440802095975,\n",
              "  0.33273515910082024,\n",
              "  0.3331450504449287,\n",
              "  0.33319553659765677,\n",
              "  0.3327368696232528,\n",
              "  0.3315417434680887,\n",
              "  0.33150216980559727,\n",
              "  0.3307428256961301,\n",
              "  0.3306533923995788,\n",
              "  0.32990586460631843,\n",
              "  0.3283420289800067,\n",
              "  0.32786998601648065,\n",
              "  0.3280172910000471],\n",
              " [2,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  70,\n",
              "  35],\n",
              " [0.33573267785711736,\n",
              "  0.3350332989073186,\n",
              "  0.3342872215829874,\n",
              "  0.33422277576327025,\n",
              "  0.33427794828497714,\n",
              "  0.334205492986327,\n",
              "  0.33438390534703133,\n",
              "  0.3343888246884619,\n",
              "  0.33405409719761914,\n",
              "  0.33376495500642805,\n",
              "  0.33353676097728774,\n",
              "  0.3336291442682521,\n",
              "  0.3333625585105671,\n",
              "  0.3340683029588867,\n",
              "  0.3336706817059606,\n",
              "  0.3337956272371163,\n",
              "  0.3323520553952923,\n",
              "  0.3324554544696766,\n",
              "  0.33263740186562957,\n",
              "  0.3330487635663176,\n",
              "  0.3330867143697134,\n",
              "  0.3325976917707962,\n",
              "  0.33138995330127385,\n",
              "  0.33133967138896986,\n",
              "  0.33056143490589013,\n",
              "  0.3304431227005986,\n",
              "  0.3297251351104058,\n",
              "  0.3281534840583845,\n",
              "  0.3276810912531726,\n",
              "  0.3278346357872153],\n",
              " [0,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  30,\n",
              "  15])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sigmoid+Sigmoid+CrossEntropy+Droupoutpercent=0.3"
      ],
      "metadata": {
        "id": "cnjpsEk5odGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = network2.Network.load_network(\"iris4-20-7-3.dat\")\n",
        "\n",
        "# Set hyper-parameter values individually after the network\n",
        "net2.set_parameters(cost=network2.CrossEntropyCost, act_hidden=network2.Sigmoid, act_output=network2.Softmax, dropoutpercent=0.3)\n",
        "\n",
        "net2.SGD(iris_train, 30, 8, 0.3, evaluation_data=iris_test, monitor_evaluation_cost=True, \n",
        "            monitor_evaluation_accuracy=True,\n",
        "            monitor_training_cost=True,\n",
        "            monitor_training_accuracy=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moLDfR-iIpCx",
        "outputId": "263058f6-ea2c-40b9-8cdb-365d8d1190f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training cost: 1.9096120823780143\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.908925721356738\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.9396331983871486\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.9390662724754582\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.896885787153784\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.8961616886548665\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.9350247420297269\n",
            "Training accuracy: 0.3333333333333333 \n",
            "test cost: 1.9324095800434045\n",
            "test accuracy: 0.3333333333333333 \n",
            "\n",
            "Training cost: 1.7462383417070335\n",
            "Training accuracy: 0.6571428571428571 \n",
            "test cost: 1.7414197480849765\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.7242729612653311\n",
            "Training accuracy: 0.34285714285714286 \n",
            "test cost: 1.7220923185684018\n",
            "test accuracy: 0.35555555555555557 \n",
            "\n",
            "Training cost: 1.3181468596202053\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.3135765288547276\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.0969251223270124\n",
            "Training accuracy: 0.9523809523809523 \n",
            "test cost: 1.0964827224212723\n",
            "test accuracy: 0.9777777777777777 \n",
            "\n",
            "Training cost: 1.1080443050114148\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.082994677946416\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.0286716961659765\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.007028559246783\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9995226314572448\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.9785321656859873\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.070635287294217\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.0456079451080238\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9198528444081056\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.8980307967507712\n",
            "test accuracy: 0.7333333333333333 \n",
            "\n",
            "Training cost: 0.945131939303624\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.9240230997969171\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.0132036039786816\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.00481439926778\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9459303350976287\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.9397513079567199\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9316825018131442\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.9254763425842822\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9902151098538209\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.97836561242509\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 1.0844102002896867\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.0561384322430878\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9341308000280495\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.9123074805759119\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9575015425945766\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 0.9334089286326367\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.767770712825116\n",
            "Training accuracy: 0.8857142857142857 \n",
            "test cost: 0.7269290633486438\n",
            "test accuracy: 0.9111111111111111 \n",
            "\n",
            "Training cost: 1.1940619760366815\n",
            "Training accuracy: 0.6666666666666666 \n",
            "test cost: 1.1199208791543602\n",
            "test accuracy: 0.6666666666666666 \n",
            "\n",
            "Training cost: 0.9233197606642792\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.8642913801082339\n",
            "test accuracy: 0.7111111111111111 \n",
            "\n",
            "Training cost: 0.7656915204381898\n",
            "Training accuracy: 0.8095238095238095 \n",
            "test cost: 0.686970358566016\n",
            "test accuracy: 0.8666666666666667 \n",
            "\n",
            "Training cost: 0.7500218413779625\n",
            "Training accuracy: 0.8095238095238095 \n",
            "test cost: 0.665840837918885\n",
            "test accuracy: 0.8666666666666667 \n",
            "\n",
            "Training cost: 0.853324116038613\n",
            "Training accuracy: 0.7047619047619048 \n",
            "test cost: 0.7977300190273653\n",
            "test accuracy: 0.7333333333333333 \n",
            "\n",
            "Training cost: 0.9095511476125732\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.8446779178936756\n",
            "test accuracy: 0.7111111111111111 \n",
            "\n",
            "Training cost: 0.9288979013567359\n",
            "Training accuracy: 0.6761904761904762 \n",
            "test cost: 0.8647074866317441\n",
            "test accuracy: 0.7111111111111111 \n",
            "\n",
            "Training cost: 0.89188930335869\n",
            "Training accuracy: 0.6857142857142857 \n",
            "test cost: 0.8464607891054577\n",
            "test accuracy: 0.7333333333333333 \n",
            "\n",
            "Training 30 epochs complete.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1.9096120823780143,\n",
              "  1.9396331983871486,\n",
              "  1.896885787153784,\n",
              "  1.9350247420297269,\n",
              "  1.7462383417070335,\n",
              "  1.7242729612653311,\n",
              "  1.3181468596202053,\n",
              "  1.0969251223270124,\n",
              "  1.1080443050114148,\n",
              "  1.0286716961659765,\n",
              "  0.9995226314572448,\n",
              "  1.070635287294217,\n",
              "  0.9198528444081056,\n",
              "  0.945131939303624,\n",
              "  1.0132036039786816,\n",
              "  0.9459303350976287,\n",
              "  0.9316825018131442,\n",
              "  0.9902151098538209,\n",
              "  1.0844102002896867,\n",
              "  0.9341308000280495,\n",
              "  0.9575015425945766,\n",
              "  0.767770712825116,\n",
              "  1.1940619760366815,\n",
              "  0.9233197606642792,\n",
              "  0.7656915204381898,\n",
              "  0.7500218413779625,\n",
              "  0.853324116038613,\n",
              "  0.9095511476125732,\n",
              "  0.9288979013567359,\n",
              "  0.89188930335869],\n",
              " [35,\n",
              "  35,\n",
              "  35,\n",
              "  35,\n",
              "  69,\n",
              "  36,\n",
              "  70,\n",
              "  100,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  70,\n",
              "  71,\n",
              "  71,\n",
              "  70,\n",
              "  70,\n",
              "  71,\n",
              "  70,\n",
              "  70,\n",
              "  71,\n",
              "  70,\n",
              "  93,\n",
              "  70,\n",
              "  71,\n",
              "  85,\n",
              "  85,\n",
              "  74,\n",
              "  71,\n",
              "  71,\n",
              "  72],\n",
              " [1.908925721356738,\n",
              "  1.9390662724754582,\n",
              "  1.8961616886548665,\n",
              "  1.9324095800434045,\n",
              "  1.7414197480849765,\n",
              "  1.7220923185684018,\n",
              "  1.3135765288547276,\n",
              "  1.0964827224212723,\n",
              "  1.082994677946416,\n",
              "  1.007028559246783,\n",
              "  0.9785321656859873,\n",
              "  1.0456079451080238,\n",
              "  0.8980307967507712,\n",
              "  0.9240230997969171,\n",
              "  1.00481439926778,\n",
              "  0.9397513079567199,\n",
              "  0.9254763425842822,\n",
              "  0.97836561242509,\n",
              "  1.0561384322430878,\n",
              "  0.9123074805759119,\n",
              "  0.9334089286326367,\n",
              "  0.7269290633486438,\n",
              "  1.1199208791543602,\n",
              "  0.8642913801082339,\n",
              "  0.686970358566016,\n",
              "  0.665840837918885,\n",
              "  0.7977300190273653,\n",
              "  0.8446779178936756,\n",
              "  0.8647074866317441,\n",
              "  0.8464607891054577],\n",
              " [15,\n",
              "  15,\n",
              "  15,\n",
              "  15,\n",
              "  30,\n",
              "  16,\n",
              "  30,\n",
              "  44,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  33,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  30,\n",
              "  41,\n",
              "  30,\n",
              "  32,\n",
              "  39,\n",
              "  39,\n",
              "  33,\n",
              "  32,\n",
              "  32,\n",
              "  33])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}